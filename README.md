# Diabetes Detection API

API para predi칞칚o de diabetes usando Machine Learning com relat칩rios diagn칩sticos explicativos gerados por LLM.

## 游닄 Tech Challenger 1

Os scripts e notebooks do **Tech Challenger 1** est칚o localizados na pasta `jupyter/tech-challenger-1/`:

- `Diabetes.ipynb` - An치lise explorat칩ria e treinamento do modelo
- `ExtraTechChallenge.ipynb` - An치lises adicionais
- `script.txt` - Scripts auxiliares

## 游빏 Tech Challenger 2

O script de **Algoritmo Gen칠tico (AG)** para otimiza칞칚o de hiperpar칙metros est치 localizado na pasta `jupyter/tech-challenger-2/`:

- `GA_train.ipynb` - Treinamento com Algoritmo Gen칠tico para otimiza칞칚o de threshold e hiperpar칙metros do modelo

## 游 Como Iniciar a API

### Op칞칚o 1: Executar Localmente (Fora do Docker)

#### macOS/Linux:

```bash
# 1. Criar e ativar ambiente virtual
python3 -m venv venv
source venv/bin/activate

# 2. Instalar depend칡ncias
pip install -r requirements.txt

# 3. Configurar vari치veis de ambiente (opcional)
# Criar arquivo .env na raiz do projeto:
# LLM_PROVIDER=ollama
# OLLAMA_HOST=http://localhost:11434
# OLLAMA_MODEL=llama3.2:1b

# 4. Iniciar a API
python -m api
```

#### Windows:

```powershell
# 1. Criar e ativar ambiente virtual
python -m venv venv
venv\Scripts\activate

# 2. Instalar depend칡ncias
pip install -r requirements.txt

# 3. Configurar vari치veis de ambiente (obrigat칩rio)
# Criar arquivo .env na raiz do projeto:
# LLM_PROVIDER=ollama
# OLLAMA_HOST=http://localhost:11434
# OLLAMA_MODEL=llama3.2:1b

# 4. Iniciar a API
python -m api
```

A API estar치 dispon칤vel em: `http://localhost:8000`

### Op칞칚o 2: Executar com Docker

#### macOS/Linux:

```bash
# 1. Criar arquivo .env na raiz (obrigat칩rio)
# LLM_PROVIDER=ollama
# OLLAMA_HOST=http://localhost:11434
# OLLAMA_MODEL=llama3.2:1b
# OPENAI_API_KEY=your_key_here
# OPENAI_MODEL=gpt-4o-mini

# 2. Construir e iniciar o container
docker compose up -d

# 3. Ver logs
docker compose logs -f diabetes-api

# 4. Parar o container
docker compose down
```

#### Windows:

```powershell
# 1. Criar arquivo .env na raiz (obrigat칩rio)
# LLM_PROVIDER=ollama
# OLLAMA_HOST=http://localhost:11434
# OLLAMA_MODEL=llama3.2:1b
# OPENAI_API_KEY=your_key_here
# OPENAI_MODEL=gpt-4o-mini

# 2. Construir e iniciar o container
docker compose up -d

# 3. Ver logs
docker compose logs -f diabetes-api

# 4. Parar o container
docker compose down
```

A API estar치 dispon칤vel em: `http://localhost:8000`

## 游늶 Endpoints Dispon칤veis

- `GET /health` - Health check
- `POST /diagnostic/invoke` - Relat칩rio diagn칩stico completo (predi칞칚o + explica칞칚o LLM)
- `POST /diagnostic/stream` - Relat칩rio diagn칩stico em streaming

## 游댢 Vari치veis de Ambiente

| Vari치vel | Descri칞칚o | Padr칚o |
|----------|-----------|--------|
| `LLM_PROVIDER` | Provedor LLM (`ollama` ou `openai`) | `ollama` |
| `OLLAMA_HOST` | URL do servidor Ollama | `http://localhost:11434` |
| `OLLAMA_MODEL` | Modelo Ollama a ser usado | `llama3.2:1b` |
| `OPENAI_API_KEY` | Chave da API OpenAI | - |
| `OPENAI_MODEL` | Modelo OpenAI a ser usado | `gpt-4o-mini` |

## 游닀 Documenta칞칚o da API

Ap칩s iniciar a API, acesse a documenta칞칚o interativa:

- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`
